---
layout: page
title: Wearable Hip Complex Assist Robot
description: Assistive  &  Interactive Robotics Lab (07.2022-07.2023), Korea Institute of Science and Technology, Seoul, South Korea
img: assets/img/KIST/KIST_title.png
importance: 98
category: Work experience
related_publications: False
---

### **<a href='https://sites.google.com/view/kist-airlab/home?authuser=0'>Assistive & Interactive Robotics Lab</a>**, AI & Robotics Institute, Korea Institute of Science and Technology, Seoul, South Korea

**PI**: Dr. Jongwon Lee

### **Achievement**: 

(1) **Robin Inho Kee**, Sangdo Kim, Wonseok Kim, Sunwoo Kim, Kanggeon Kim, Jongwon Lee, “Deep Learning in Exoskeleton Systems for Enhanced Gait Assessment and Sarcopenia Identification", In preparation

(2) Hobin Kim, Jongbok Lee, Sunwoo Kim, **Inho Kee**, Sangdo Kim, Shinsuk Park, Kanggeon Kim, Jongwon Lee, “Gait Phase Estimation Method Adaptable to Changes in Gait Speed on Level Ground and Stairs”, The Journal of Korea Robotics Society, 2023

### **Project**: **Deep Learning in Exoskeleton Systems for Enhanced Gait Assessment and Sarcopenia Identification**


**Abstract**: 

Our work presents a novel deep learning (DL) approach to remote and non-intrusive gait assessments for assistive exoskeleton users, specifically targeting the identification of sarcopenia, a condition characterized by the age-related loss of muscle mass and strength. Sarcopenia significantly impacts walking ability, leading to reduced mobility and quality of life, particularly in older adults. Traditional clinical gait assessments are often inconvenient, leading to irregular visits and missed opportunities for early intervention.

To address these challenges, we propose utilizing the existing exoskeleton system, MoonWalk, which patients already use for daily assistance. MoonWalk is a 4 DOF wearable system equipped with encoders, an inertial measurement unit (IMU), and instrumented smart insoles. These sensors enable continuous monitoring of gait characteristics without the need for additional devices. Our DL model, based on BiLSTM networks and multi-head attention mechanisms, estimates foot position and computes clinically relevant gait parameters, including stride length, swing width, and foot clearance.

We collected gait data from 20 healthy subjects and 10 sarcopenia patients using the MoonWalk system, with ground truth foot positions recorded by a visual motion capture system. Our model's performance was evaluated against this ground truth, showing high accuracy. The estimated gait parameters were then used to differentiate between healthy individuals and sarcopenia patients using logistic regression and support vector machines (SVMs), with a 100% accuracy, demonstrating the potential for early detection and intervention. This approach offers a promising solution for improving the quality of life and mobility for those affected by sarcopenia through continuous, in-home monitoring and assessment.

<div class="row">
    <div class="col-sm-12 mt-3 mt-md-0">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/K9j5tbMQyQ8?si=jzIWZHkj6rxLiq0p" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </div>
</div>
<div class="caption">
    Overview video of the wearable hip complex assist robot project.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_system.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Hardware overview.
</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_model.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Model overview.
</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_result.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Temporary result of gait assesment.
</div>


### **What I did**:

(1) Developed a deep learning model for estimating foot trajectory by fusing data from hip exoskeleton and insole sensors, achieving 100% accuracy in identifying sarcopenia patients through gait parameter analysis.

(2) Led and administered motion capture system (Motion Analysis) experiments over 40 subjects, including patients and outdoor hiking experiments over 200km.

<div class="row">
    <div class="col-sm-12 mt-3 mt-md-0">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/WNiAA-gsbOs?si=T-_nhnDrN_3QO33I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </div>
</div>
<div class="caption">
    Outdoor hiking experiment - World's First Wearable Robot Challenge in the Wild.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_exp.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Endless treadmill walking experiments.
</div>




etc. 
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_labmember.jpg" title="fab image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_Me.jpg" title="fab image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>