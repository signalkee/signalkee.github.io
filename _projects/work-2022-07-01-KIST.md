---
layout: page
title: Wearable Hip Complex Assist Robot
description: Assistive  &  Interactive Robotics Lab (07.2022-07.2023), Korea Institute of Science and Technology, Seoul, South Korea
img: assets/img/KIST/KIST_title.gif
importance: 98
category: Work experience
related_publications: False
---

#### **<a href='https://sites.google.com/view/kist-airlab/home?authuser=0'>Assistive & Interactive Robotics Lab</a>**
#### AI & Robotics Institute, Korea Institute of Science and Technology, Seoul, South Korea

**PI**: Dr. Jongwon Lee

#### **Achievement**: 

(1) Sangdo Kim*, Jeonguk Kang* (*: Equal Contribution), Robin Inho Kee, Sunwoo Kim, Choa Kim, Youngsu Cha, Yisoo Lee, Kanggeon Kim, Jongwon Lee, “Towards Daily Life Sarcopenia Detection: Deep Learning-Based Gait Analysis Using Wearable Hip Assistive Robot", Under review

(2) Hobin Kim, Jongbok Lee, Sunwoo Kim, **Inho Kee**, Sangdo Kim, Shinsuk Park, Kanggeon Kim, Jongwon Lee, “Gait Phase Estimation Method Adaptable to Changes in Gait Speed on Level Ground and Stairs”, The Journal of Korea Robotics Society, 2023

#### **Project**: **Towards Daily Life Sarcopenia Detection: Deep Learning-Based Gait Analysis Using Wearable Hip Assistive Robot**


**Abstract**: 

Daily assistive wearable exoskeletons not only support walking but also monitor individual gait patterns, providing insights into functional and health status. By extracting gait parameters that reflect physical condition, these systems enable early detection of abnormalities, intervention evaluation, and personalized feedback. In this study, we developed a deep learning-based model to estimate gait parameters using data from 22 healthy individuals and 15 sarcopenia patients. Experiments at various walking speeds in both treadmill and overground environments ensured robustness. The proposed model achieved high accuracy, with RMSE values below 7
cm for stride length, 2 cm for swing width, and 2 cm for foot clearance. Integrating the estimated gait parameters into an SVM-based classifier improved sarcopenia classification accuracy from 91.71% to 94.37%, surpassing results obtained using robotic sensor data alone. These findings highlight the effectiveness of the proposed approach and its potential for real-world and clinical applications, advancing early detection, personalized gait assessment, and adaptive rehabilitation using daily assistive exoskeletons.

<div class="row">
    <div class="col-sm-12 mt-3 mt-md-0">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/K9j5tbMQyQ8?si=jzIWZHkj6rxLiq0p" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </div>
</div>
<div class="caption">
    Overview video of the wearable hip complex assist robot project.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_system.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Hardware overview.
</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_model.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Model overview.
</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_result.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Temporary result of gait assesment.
</div>


#### **What I did**:

(1) Developed a deep learning model for estimating foot trajectory by fusing data from hip exoskeleton and insole sensors, achieving 100% accuracy in identifying sarcopenia patients through gait parameter analysis.

(2) Led and administered motion capture system (Motion Analysis) experiments over 40 subjects, including patients and outdoor hiking experiments over 200km.

<div class="row">
    <div class="col-sm-12 mt-3 mt-md-0">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/WNiAA-gsbOs?si=T-_nhnDrN_3QO33I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </div>
</div>
<div class="caption">
    Outdoor hiking experiment - World's First Wearable Robot Challenge in the Wild.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_exp.png" title="intro image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Treadmill walking experiments.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_exp_overground.gif" title="fab image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_exp_sidewalk.gif" title="fab image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_exp_sitstand.gif" title="fab image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Extra experiments.
</div>


etc. 
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_labmember.jpg" title="fab image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/KIST/KIST_Me.jpg" title="fab image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>